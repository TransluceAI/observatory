# Examples to be used in a few-shot prompt for generating and simulating neuron explanations.

from dataclasses import dataclass
from typing import List, Optional, Tuple

from activations.activations import ActivationRecord


@dataclass
class Example:
    token_activation_pairs_list: List[List[Tuple[str, int]]]
    explanation: str
    first_reveal_indices: Optional[List[int]]
    """
    Contains one index per activation record, representing the index for which
    the activation value first becomes releaved instead of being "unknown"
    in the few-shot prompt.

    See ``Step 2: Simulate the neuron's behavior using the explanations''
    in Bills et al., 2023.
    """


def get_examples_for_fewshot() -> List[Example]:
    return DEFAULT_EXAMPLES


def format_example(
    token_activation_pairs_list: List[List[Tuple[str, int]]],
    first_reveal_indices: Optional[List[int]] = None,
    omit_zeros: bool = False,
):
    """Assumes activations are normalized and discretized to the range [0, 10]."""
    sequence_strs: List[str] = []
    for idx, token_activation_pairs in enumerate(token_activation_pairs_list):
        fr_idx = 0 if first_reveal_indices is None else first_reveal_indices[idx]

        if omit_zeros:
            assert fr_idx == 0, "Can't hide activations and omit zeros"
            filtered_token_activation_pairs: List[Tuple[str, int]] = []
            for token, act in token_activation_pairs:
                if act > 0:
                    filtered_token_activation_pairs.append((token, act))
            token_activation_pairs = filtered_token_activation_pairs

        entries: List[str] = []
        for i, (token, act) in enumerate(token_activation_pairs):
            assert act >= 0 and act <= 10, "Activations must be in range [0, 10]"
            act_str = "unknown" if i < fr_idx else str(int(act))
            entries.append(f"{token}\t{act_str}")
        if entries:
            sequence_strs.append("\n".join(entries))
    if not sequence_strs:
        return ""
    return "\n<start>\n" + "\n<end>\n<start>\n".join(sequence_strs) + "\n<end>\n"


# These are used for the non-fine-tuned simulator.
DEFAULT_EXAMPLES = [
    # From neuron (5, 14249).
    Example(
        token_activation_pairs_list=[
            # Maximally activating exemplar 0 [9 : 9 + 34].
            [
                (" trails", 0),
                (".", 0),
                (" For", 0),
                (" Back", 0),
                ("country", 0),
                (" adventurers", 0),
                (",", 0),
                (" the", 0),
                (" Bolton", 3),
                (" Back", 0),
                ("country", 0),
                (" is", 0),
                (" second", 0),
                (" to", 0),
                (" none", 0),
                (" in", 0),
                (" the", 0),
                (" Eastern", 10),
                (" States", 0),
                (",", 0),
                (" with", 0),
                (" ", 0),
                ("150", 0),
                ("0", 0),
                (" acres", 0),
                (" of", 0),
                (" beautiful", 0),
                (" terrain", 0),
                (" right", 0),
                (" out", 0),
                (" of", 0),
                (" the", 0),
                (" gates", 0),
                (",", 0),
            ],
            # Maximally activating exemplar 1 [20 : 20 + 34].
            [
                ("wood", 0),
                (" that", 0),
                (" may", 0),
                (" naturally", 0),
                (" grow", 0),
                (" better", 0),
                (" further", 0),
                (" up", 0),
                (" the", 0),
                (" coast", 0),
                ("?", 0),
                (" Should", 0),
                (" we", 0),
                (" be", 0),
                (" reint", 0),
                ("roducing", 0),
                (" native", 0),
                (" North", 0),
                (" American", 1),
                (" plants", 0),
                (" that", 0),
                (" arrived", 0),
                (" here", 0),
                (" from", 0),
                (" the", 0),
                (" east", 8),
                (" coast", 5),
                (" ", 0),
                ("200", 0),
                ("0", 0),
                (" years", 0),
                (" ago", 0),
                (",", 0),
                (" or", 0),
            ],
            # Maximally activating exemplar 3 [0 : 0 + 34].
            [
                (":", 0),
                ("52", 0),
                (" -", 0),
                ("040", 8),
                ("0", 0),
                (",", 0),
                (' "', 0),
                ("P", 0),
                (".", 0),
                (" J", 0),
                (".", 0),
                (" All", 0),
                ("ing", 0),
                ('"\n', 0),
                ("<", 0),
                ("web", 0),
                ("st", 0),
                ("ert", 0),
                ("went", 0),
                ("ys", 0),
                ("ix", 0),
                (" at", 0),
                (" gmail", 0),
                (".com", 0),
                (">", 0),
                (" wrote", 0),
                (":\n", 0),
                (">", 0),
                (" Sometimes", 0),
                (" even", 0),
                (" an", 0),
                (" old", 0),
                (" news", 0),
                ("y", 0),
            ],
        ],
        first_reveal_indices=[15, 6, 2],
        explanation="concepts related to the East Coast of North America",
    ),
    # From neuron (15, 123).
    Example(
        token_activation_pairs_list=[
            # Maximally activating exemplar 0 [15: 15 + 34].
            [
                (" are", 0),
                (" a", 0),
                (" lot", 0),
                (" of", 0),
                (" us", 0),
                (" (", 0),
                ("and", 0),
                (" I", 0),
                (" hope", 0),
                (" there", 0),
                (" are", 0),
                ("!)", 0),
                (" we", 0),
                ("'ll", 0),
                (" divide", 0),
                (" into", 0),
                (" breakout", 1),
                (" rooms", 6),
                (" so", 2),
                (" we", 4),
                (" can", 4),
                (" spend", 1),
                (" time", 2),
                (" getting", 1),
                (" to", 10),
                (" know", 0),
                (" a", 0),
                (" few", 0),
                (" people", 1),
                (" better", 1),
                (".", 4),
                (" Perhaps", 1),
                (" you", 1),
                ("'d", 0),
            ],
            # Maximally activating exemplar 2 [0: 0 + 34].
            [
                (" Conference", 0),
                (" Meeting", 0),
                (":", 0),
                (" Join", 2),
                (" Zoom", 6),
                (" Meeting", 5),
                (" -", 3),
                (" click", 1),
                (" on", 1),
                (" this", 0),
                (" link", 2),
                (":", 5),
                ("https", 2),
                ("://", 8),
                ("zoom", 4),
                (".us", 3),
                ("/j", 3),
                ("/", 9),
                ("968", 3),
                ("150", 5),
                ("570", 4),
                ("?", 2),
                ("pwd", 1),
                ("=", 0),
                ("WH", 0),
                ("dx", 0),
                ("Y", 0),
                ("3", 0),
                ("Ba", 0),
                ("ek", 0),
                ("9", 0),
                ("y", 0),
                ("WG", 0),
                ("Z", 0),
            ],
            # Maximally activating exemplar 3 [10: 10 + 34].
            [
                (" pm", 0),
                (" -", 0),
                (" ", 1),
                ("8", 0),
                (" pm", 0),
                (" PST", 3),
                ("\n", 4),
                ("Zoom", 9),
                (" Meeting", 7),
                (" Information", 5),
                (":\n", 7),
                ("When", 4),
                (":", 4),
                (" Jul", 1),
                (" ", 4),
                ("22", 3),
                (",", 5),
                (" ", 4),
                ("202", 0),
                ("0", 3),
                (" ", 3),
                ("06", 1),
                (":", 2),
                ("30", 3),
                (" PM", 4),
                (" Vancouver", 0),
                ("\n", 7),
                ("Topic", 3),
                (":", 3),
                (" P", 0),
                ("PR", 0),
                ("P", 1),
                (" Web", 4),
                ("inar", 3),
            ],
        ],
        first_reveal_indices=[6, 2, 4],
        explanation="references to post-covid virtual communication platforms, online meetings, and events.",
    ),
]


# These are used in the bills et al formatted prompt for the explainer.
BILLS_EXAMPLES: List[Tuple[str, List[ActivationRecord]]] = [
    # Example 1
    (
        "present tense verbs ending in 'ing'",
        [
            ActivationRecord(
                tokens=[
                    "t",
                    "urt",
                    "ur",
                    "ro",
                    " is",
                    " fab",
                    "ulously",
                    " funny",
                    " and",
                    " over",
                    " the",
                    " top",
                    " as",
                    " a",
                    " '",
                    "very",
                    " sneaky",
                    "'",
                    " but",
                    "ler",
                    " who",
                    " excel",
                    "s",
                    " in",
                    " the",
                    " art",
                    " of",
                    " impossible",
                    " disappearing",
                    "/",
                    "re",
                    "app",
                    "earing",
                    " acts",
                ],
                activations=[
                    -0.71,
                    -1.85,
                    -2.39,
                    -2.58,
                    -1.34,
                    -1.92,
                    -1.69,
                    -0.84,
                    -1.25,
                    -1.75,
                    -1.42,
                    -1.47,
                    -1.51,
                    -0.8,
                    -1.89,
                    -1.56,
                    -1.63,
                    0.44,
                    -1.87,
                    -2.55,
                    -2.09,
                    -1.76,
                    -1.33,
                    -0.88,
                    -1.63,
                    -2.39,
                    -2.63,
                    -0.99,
                    2.83,
                    -1.11,
                    -1.19,
                    -1.33,
                    4.24,
                    -1.51,
                ],
            ),
            ActivationRecord(
                tokens=[
                    "esc",
                    "aping",
                    " the",
                    " studio",
                    " ,",
                    " pic",
                    "col",
                    "i",
                    " is",
                    " warm",
                    "ly",
                    " affecting",
                    " and",
                    " so",
                    " is",
                    " this",
                    " ad",
                    "roit",
                    "ly",
                    " minimalist",
                    " movie",
                    " .",
                ],
                activations=[
                    -0.69,
                    4.12,
                    1.83,
                    -2.28,
                    -0.28,
                    -0.79,
                    -2.2,
                    -2.03,
                    -1.77,
                    -1.71,
                    -2.44,
                    1.6,
                    -1,
                    -0.38,
                    -1.93,
                    -2.09,
                    -1.63,
                    -1.94,
                    -1.82,
                    -1.64,
                    -1.32,
                    -1.92,
                ],
            ),
        ],
    ),
    # Example 2
    (
        "words related to physical medical conditions",
        [
            ActivationRecord(
                tokens=[
                    "as",
                    " sac",
                    "char",
                    "ine",
                    " movies",
                    " go",
                    " ,",
                    " this",
                    " is",
                    " likely",
                    " to",
                    " cause",
                    " massive",
                    " cardiac",
                    " arrest",
                    " if",
                    " taken",
                    " in",
                    " large",
                    " doses",
                    " .",
                ],
                activations=[
                    -0.14,
                    -1.37,
                    -0.68,
                    -2.27,
                    -1.46,
                    -1.11,
                    -0.9,
                    -2.48,
                    -2.07,
                    -3.49,
                    -2.16,
                    -1.79,
                    -0.23,
                    -0.04,
                    4.46,
                    -1.02,
                    -2.26,
                    -2.95,
                    -1.49,
                    -1.46,
                    -0.6,
                ],
            ),
            ActivationRecord(
                tokens=[
                    "shot",
                    " perhaps",
                    " '",
                    "art",
                    "istically",
                    "'",
                    " with",
                    " handheld",
                    " cameras",
                    " and",
                    " apparently",
                    " no",
                    " movie",
                    " lights",
                    " by",
                    " jo",
                    "aquin",
                    " b",
                    "aca",
                    "-",
                    "as",
                    "ay",
                    " ,",
                    " the",
                    " low",
                    "-",
                    "budget",
                    " production",
                    " swings",
                    " annoy",
                    "ingly",
                    " between",
                    " vert",
                    "igo",
                    " and",
                    " opacity",
                    " .",
                ],
                activations=[
                    -0.09,
                    -3.53,
                    -0.72,
                    -2.36,
                    -1.05,
                    -1.12,
                    -2.49,
                    -2.14,
                    -1.98,
                    -1.59,
                    -2.62,
                    -2,
                    -2.73,
                    -2.87,
                    -3.23,
                    -1.11,
                    -2.23,
                    -0.97,
                    -2.28,
                    -2.37,
                    -1.5,
                    -2.81,
                    -1.73,
                    -3.14,
                    -2.61,
                    -1.7,
                    -3.08,
                    -4,
                    -0.71,
                    -2.48,
                    -1.39,
                    -1.96,
                    -1.09,
                    4.37,
                    -0.74,
                    -0.5,
                    -0.62,
                ],
            ),
        ],
    ),
    # Example 3
    (
        "phrases related to community",
        [
            ActivationRecord(
                tokens=[
                    "the",
                    " sense",
                    " of",
                    " together",
                    "ness",
                    " in",
                    " our",
                    " town",
                    " is",
                    " strong",
                    " .",
                ],
                activations=[
                    0,
                    0,
                    0,
                    1,
                    2,
                    0,
                    0.23,
                    0.5,
                    0,
                    0,
                    0,
                ],
            ),
            ActivationRecord(
                tokens=[
                    "a",
                    " buoy",
                    "ant",
                    " romantic",
                    " comedy",
                    " about",
                    " friendship",
                    " ,",
                    " love",
                    " ,",
                    " and",
                    " the",
                    " truth",
                    " that",
                    " we",
                    "'re",
                    " all",
                    " in",
                    " this",
                    " together",
                    " .",
                ],
                activations=[
                    -0.15,
                    -2.33,
                    -1.4,
                    -2.17,
                    -2.53,
                    -0.85,
                    0.23,
                    -1.89,
                    0.09,
                    -0.47,
                    -0.5,
                    -0.58,
                    -0.87,
                    0.22,
                    0.58,
                    1.34,
                    0.98,
                    2.21,
                    2.84,
                    1.7,
                    -0.89,
                ],
            ),
        ],
    ),
]
